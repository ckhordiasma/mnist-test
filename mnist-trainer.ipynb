{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Install TensorFlow\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mnist_test = (pd.read_csv(\"./input/mnist-in-csv/mnist_test.csv\")).to_numpy()\n",
    "mnist_train = (pd.read_csv(\"./input/mnist-in-csv/mnist_train.csv\")).to_numpy()\n",
    "x_test = mnist_test[:,1:] \n",
    "x_train = mnist_train[:,1:]\n",
    "\n",
    "x_test = np.reshape(x_test,(x_test.shape[0],28,-1))\n",
    "x_train = np.reshape(x_train,(x_train.shape[0],28,-1))\n",
    "\n",
    "y_test = mnist_test[:,0]\n",
    "y_train = mnist_train[:,0]\n",
    "\n",
    "x_train = x_train[...,tf.newaxis]\n",
    "x_test = x_test[...,tf.newaxis]\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28,1)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_ = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28,1)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model1_.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(28, 28,1)),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 60000 samples\nEpoch 1/5\n60000/60000 [==============================] - 5s 83us/sample - loss: 0.2853 - accuracy: 0.9184\nEpoch 2/5\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.1425 - accuracy: 0.9574\nEpoch 3/5\n60000/60000 [==============================] - 4s 70us/sample - loss: 0.1050 - accuracy: 0.9682\nEpoch 4/5\n60000/60000 [==============================] - 4s 69us/sample - loss: 0.0874 - accuracy: 0.9733\nEpoch 5/5\n60000/60000 [==============================] - 4s 68us/sample - loss: 0.0759 - accuracy: 0.9762\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x17fc985ab48>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 60000 samples\nEpoch 1/20\n60000/60000 [==============================] - 5s 77us/sample - loss: 0.2949 - accuracy: 0.9143\nEpoch 2/20\n60000/60000 [==============================] - 4s 68us/sample - loss: 0.1426 - accuracy: 0.9575\nEpoch 3/20\n60000/60000 [==============================] - 4s 69us/sample - loss: 0.1057 - accuracy: 0.9688\nEpoch 4/20\n60000/60000 [==============================] - 4s 68us/sample - loss: 0.0859 - accuracy: 0.9735\nEpoch 5/20\n60000/60000 [==============================] - 4s 69us/sample - loss: 0.0735 - accuracy: 0.9774\nEpoch 6/20\n60000/60000 [==============================] - 4s 68us/sample - loss: 0.0631 - accuracy: 0.9796\nEpoch 7/20\n60000/60000 [==============================] - 4s 69us/sample - loss: 0.0569 - accuracy: 0.9816\nEpoch 8/20\n60000/60000 [==============================] - 4s 70us/sample - loss: 0.0520 - accuracy: 0.9833\nEpoch 9/20\n60000/60000 [==============================] - 4s 68us/sample - loss: 0.0466 - accuracy: 0.9844\nEpoch 10/20\n60000/60000 [==============================] - 4s 68us/sample - loss: 0.0434 - accuracy: 0.9851\nEpoch 11/20\n60000/60000 [==============================] - 4s 70us/sample - loss: 0.0396 - accuracy: 0.9866\nEpoch 12/20\n60000/60000 [==============================] - 4s 70us/sample - loss: 0.0379 - accuracy: 0.9872\nEpoch 13/20\n60000/60000 [==============================] - 4s 70us/sample - loss: 0.0353 - accuracy: 0.9880\nEpoch 14/20\n60000/60000 [==============================] - 4s 69us/sample - loss: 0.0323 - accuracy: 0.9888\nEpoch 15/20\n60000/60000 [==============================] - 4s 71us/sample - loss: 0.0319 - accuracy: 0.9894\nEpoch 16/20\n60000/60000 [==============================] - 4s 71us/sample - loss: 0.0295 - accuracy: 0.9901\nEpoch 17/20\n60000/60000 [==============================] - 4s 71us/sample - loss: 0.0292 - accuracy: 0.9906\nEpoch 18/20\n60000/60000 [==============================] - 4s 69us/sample - loss: 0.0260 - accuracy: 0.9909\nEpoch 19/20\n60000/60000 [==============================] - 4s 69us/sample - loss: 0.0261 - accuracy: 0.9916\nEpoch 20/20\n60000/60000 [==============================] - 4s 69us/sample - loss: 0.0250 - accuracy: 0.9914\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1801e644e48>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_.fit(x_train, y_train, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 60000 samples\nEpoch 1/20\n60000/60000 [==============================] - 8s 135us/sample - loss: 0.1423 - accuracy: 0.9556\nEpoch 2/20\n60000/60000 [==============================] - 6s 101us/sample - loss: 0.0450 - accuracy: 0.9856\nEpoch 3/20\n60000/60000 [==============================] - 6s 100us/sample - loss: 0.0339 - accuracy: 0.9898\nEpoch 4/20\n60000/60000 [==============================] - 6s 102us/sample - loss: 0.0257 - accuracy: 0.9916\nEpoch 5/20\n60000/60000 [==============================] - 6s 103us/sample - loss: 0.0208 - accuracy: 0.9936\nEpoch 6/20\n60000/60000 [==============================] - 6s 102us/sample - loss: 0.0195 - accuracy: 0.9935\nEpoch 7/20\n60000/60000 [==============================] - 6s 98us/sample - loss: 0.0148 - accuracy: 0.9950\nEpoch 8/20\n60000/60000 [==============================] - 6s 101us/sample - loss: 0.0141 - accuracy: 0.9952\nEpoch 9/20\n60000/60000 [==============================] - 6s 102us/sample - loss: 0.0121 - accuracy: 0.9963\nEpoch 10/20\n60000/60000 [==============================] - 6s 100us/sample - loss: 0.0128 - accuracy: 0.9960\nEpoch 11/20\n60000/60000 [==============================] - 6s 100us/sample - loss: 0.0106 - accuracy: 0.9966\nEpoch 12/20\n60000/60000 [==============================] - 7s 108us/sample - loss: 0.0093 - accuracy: 0.9969\nEpoch 13/20\n60000/60000 [==============================] - 6s 103us/sample - loss: 0.0098 - accuracy: 0.9968\nEpoch 14/20\n60000/60000 [==============================] - 6s 100us/sample - loss: 0.0089 - accuracy: 0.9972\nEpoch 15/20\n60000/60000 [==============================] - 6s 108us/sample - loss: 0.0076 - accuracy: 0.9975\nEpoch 16/20\n60000/60000 [==============================] - 6s 107us/sample - loss: 0.0089 - accuracy: 0.9976\nEpoch 17/20\n60000/60000 [==============================] - 6s 102us/sample - loss: 0.0073 - accuracy: 0.9979\nEpoch 18/20\n60000/60000 [==============================] - 6s 102us/sample - loss: 0.0066 - accuracy: 0.9981\nEpoch 19/20\n60000/60000 [==============================] - 6s 103us/sample - loss: 0.0072 - accuracy: 0.9980\nEpoch 20/20\n60000/60000 [==============================] - 6s 102us/sample - loss: 0.0081 - accuracy: 0.9976\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x18007a040c8>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "10000/1 - 1s - loss: 0.0358 - accuracy: 0.9791\n10000/1 - 1s - loss: 0.0406 - accuracy: 0.9800\n10000/1 - 1s - loss: 0.0249 - accuracy: 0.9898\n"
    },
    {
     "data": {
      "text/plain": "[0.04679883110938446, 0.9898]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_test,  y_test, verbose=2)\n",
    "model1_.evaluate(x_test,  y_test, verbose=2)\n",
    "model2.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('mnist.h5')\n",
    "model1_.save('mnist_.h5')\n",
    "model2.save('mnistconv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}